# Modeling Efficient Humanitarian Aid Distribution in a Stochastic Environment

We created a Markov Decision Process modeling a disaster relief scenario in which an agent can take an action from a finite set (cash, personnel, natural resources) which stochastically reduces the severity of pre-defined issues (food shortage, infrastructure damage, civil unrest, political turmoil). Various approaches to train an agent in making decisions about actions efficiently and effectively yield different results. We compare the performance of our agent and the model to human performance as an estimate of real-world applicability. This framework and infrastructure of training and analysis can later be fine tuned to a domain specific disaster such as a regional earthquake or flood and provide automated insights to effective decision making in order to guide experts in allocating resources for more efficient relief.
